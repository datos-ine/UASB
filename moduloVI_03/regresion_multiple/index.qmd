---
format: 
  revealjs: 
    chalkboard: true
    logo: logos_ine.png
    incremental: true
    slide-number: true
    scrollable: false
    css: custom.css
---

```{r}
#| echo: false
# Configuración global
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center")

# Paquetes necesarios
pacman::p_load(
  performance,
  plotly,
  flextable,
  rio,
  janitor,
  tidyverse
)

# Carga datos
datos <- read_csv2("../cancer_USA.txt")
```

## Módulo VI: Análisis Epidemiológico Avanzado {.center style="text-align: center;"}

:::: {style="margin-top: 1.5em;"}
Docentes: Tamara Ricardo, Christian Ballejo

::: {style="font-size: .75em; margin-bottom: 1.5em;"}
Programa de Maestría en Epidemiología para la Salud Pública
:::

![](logos_ine.png){fig-align="center" width="70%"}
::::

## PROGRAMA DE LA UNIDAD

::: {style="margin-top:1.5em;"}
```{r}
# Genera datos para la tabla 
tibble(
  Semana = c(rep("30 oct. al 03 nov. 2024", 2), 
             rep("06 al 09 nov. 2024", 2),
             "13 al 16 nov. 2024", ""),      
  
      Tema = c("- Introducción a los Paquetes y Lenguajes Estadístico. Diferencias entre interfaces gráficas (GUI) y de línea de comandos (CLI). Comparativa entre software privativo y gratuito/open source.",
               "- R y R-Commander. Navegación del menú. Lectura e importación de archivos de datos. Estadística descriptiva. Agrupamiento de variables. Manejo de factores. Guardado de scripts y resultados. Paquetes y plugins.",
               "- Relación entre variables numéricas. Covarianza y representación gráfica. Limitaciones. Correlación de Pearson: interpretación del signo y la magnitud.Visualización con correlogramas. Métodos no paramétricos: correlación de Spearman y de Kendall.",
               "- Introducción al Modelado Estadístico. Modelo lineal general: concepto y supuestos. Bondad de ajuste y análisis de residuos. Regresión lineal simple y análisis de la varianza (ANOVA). Interpretación de los resultados.",
               "- Regresión Lineal Múltiple. Selección de variables explicativas y control de multicolinealidad. Análisis e interpretación de residuos.",
               "- Confusión e Interacción. Identificación y roles de las covariables. Control y detección de la confusión. Interpretación de resultados en presencia de interacción.")
      ) |>    
  
  #  Genera tabla    
  flextable() |>    
  bold(part = "header") |> 
  fontsize(size = 16, part = "all") |>   
  merge_v() |>  
  color(i = c(1:4, 6), color = "gray40") |> 
  highlight(i = 5, color = "#FFB90F") |> 
  autofit() 
```
:::

## ESTRUCTURA DE LA CLASE

::: {style="margin-top: 2em;"}
```{r}
# Genera datos para la tabla
tibble(
  Tiempo = c("18:30hs", 
             "18:40hs", 
             "20:00hs",
             "20:15hs", 
             "21:30hs"),
  
  Descripción = c("Ingreso a la videollamada", 
                  "Inicio de la clase",
                  "Receso", 
                  "Continuación clase", 
                  "Cierre")
) |> 
  
  #  Genera tabla    
  flextable() |>    
  bold(part = "header") |> 
  fontsize(size = 20, part = "all") |>   
  merge_v() |>  
  autofit() 
```
:::

## OBJETIVOS

-   Definir la **regresión lineal múltiple** y su aplicación en el análisis de datos.

-   Explicar el significado de los **coeficientes** en términos de cambio en la variable dependiente.

-   Evaluar **colinealidad** y su impacto en el modelo.

-   Introducir métodos de **selección de variables**.

## Regresión lineal múltiple (RLM)

-   Analiza el efecto de dos o más variables independientes ($X_1$, $X_2$,...$X_k$) sobre la variable respuesta ($Y$).

-   Aplicaciones:

    -   Cuantificar el efecto de múltiples variables sobre $Y$.

    -   Analizar la **dirección** y **magnitud** de la asociación.

    -   Evaluar la capacidad **explicativa** y **predictiva** del modelo.

    -   Detectar **interacción** y **confusión** entre variables.

------------------------------------------------------------------------

-   El modelo matemático para la regresión múltiple es:

    $$
    Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ...+\beta_kX_k +\epsilon
    $$

-   Donde:

    -   $\beta_0$: Intercepto, valor esperado de $Y$ cuando todas las otras variables son iguales a cero.

    -   $\beta_1$: Pendiente de $X_1$, mide el cambio en $Y$ por cada unidad de incremento en $X_1$, manteniendo constante $X_2$.

    -   $\beta_2$: Pendiente de $X_2$, mide el cambio en $Y$ por cada unidad de incremento en $X_2$, manteniendo constante $X_1$.

------------------------------------------------------------------------

#### Supuestos del modelo de regresión múltiple

-   **Independencia**:

    -   Las observaciones son independientes.

    -   Cuando no hay interacción, el efecto de $X_1$ ​no depende de $X_2$, y viceversa.

-   **Linealidad**:

    -   El valor medio de $Y$ es una función lineal de $X_1, X_2, \dots, X_n$.

    -   Se puede extender para incluir términos cuadráticos o interacciones.

------------------------------------------------------------------------

-   **Homocedasticidad**:

    -   La varianza de $Y$ es constante a través de los valores de $X_1, X_2, \dots, X_n$.

-   **Normalidad**:

    -   Los valores de $Y$ tienen una distribución normal para cada combinación de $X_1, X_2, \dots, X_n$.

------------------------------------------------------------------------

#### Representación gráfica

-   Debido a sus características, el modelo de regresión múltiple no puede representarse por una recta representada en un plano de dos variables ($X$ e $Y$).

-   En un modelo de regresión con dos predictores, la relación entre $X_1, X_2$ e $Y$ se representa como un **plano en el espacio tridimensional**.

------------------------------------------------------------------------

```{r}
# Sample data
set.seed(123)

data <- tibble(
  x1 = rnorm(100), 
  x2 = rnorm(100), 
  y = 2 * x1 + 3 * x2 + rnorm(100)
)

error <- rnorm(100, mean = 0, sd = 0.5)

# Fit multiple linear regression model
model <- lm(y ~ x1 + x2, data = data)

# Generate points for the plane
x1_range <- range(data$x1)

x2_range <- range(data$x2)

x1_grid <- seq(x1_range[1], x1_range[2], length.out = 20)

x2_grid <- seq(x2_range[1], x2_range[2], length.out = 20)

grid <- expand.grid(x1 = x1_grid, x2 = x2_grid)

grid$y <- predict(model, newdata = grid)

# Plot
plot_ly(data = data, x = ~ x1, y = ~ x2, z = ~ y) |>
  
  add_markers(error_x = list(array = error), 
              error_y = list(array = error),
              showlegend = F) |> 
  
  add_surface(x = ~ x1_grid, y = ~ x2_grid,
              z = ~ matrix(grid$y, 
                           nrow = length(x1_grid), 
                           ncol = length(x2_grid)),
              showscale = F, opacity = .75) |>

  layout(scene = list(xaxis = list(title = "X1"),
                      yaxis = list(title = "X2"),
                      zaxis = list(title = "Y")))
```

------------------------------------------------------------------------

## Ejemplo en R Commander

-   Abrimos R Commander con `library(Rcmdr)`.

-   Desde el menú **Herramientas \> Cargar paquetes** activamos las librerías `performance` y `emmeans`.

-   Vamos al menú **Datos \> Importar datos \> Desde archivo de texto, portapapeles o URL...** y cargamos el archivo `cancer_USA.txt`.

------------------------------------------------------------------------

-   Vamos al menú **Estadísticos \> Ajuste de modelos \> Modelo lineal**.

-   Seleccionamos `tasa_mortalidad` como variable dependiente (casilla izquierda).

-   Seleccionamos las variables `mediana_edad_cat`, `pct_pobreza`, `pct_desempleo` y `pct_salud_publica` como variables explicativas y las colocamos en la casilla de la derecha unidas por el signo `+` y presionamos **Aceptar**.

------------------------------------------------------------------------

![](images/clipboard-2166872651.png){fig-align="center"}

------------------------------------------------------------------------

-   Obtendremos la siguiente salida:

    ```{r}
    # Ajuste modelo
    mod1 <- lm(tasa_mortalidad ~ pct_salud_publica + pct_pobreza + pct_desempleo +
                 mediana_edad_cat, 
               data = datos)

    summary(mod1)
    ```

------------------------------------------------------------------------

-   Donde:

    -   `pct_salud_publica` ($\beta_1$): cambio en $Y$ cuando aumenta 1% la cobertura pública de salud, manteniendo constantes las otras variables.

    -   `pct_pobreza` ($\beta_2$): cambio en $Y$ cuando aumenta 1% la pobreza, manteniendo constantes las otras variables.

    -   `pct_desempleo` ($\beta_3$): cambio en $Y$ cuando aumenta 1% el desempleo, manteniendo constantes las otras variables.

    -   `mediana_edad_cat`: cambio en $Y$ respecto de la categoría de referencia (23-35 años).

------------------------------------------------------------------------

-   Si quisiéramos comparar que grupos de edad son diferentes entre sí, debemos realizar el test de comparaciones múltiples con `emmeans` usando el código:

    `emmeans(mod1, specs = "mediana_edad_cat", contr = "pairwise")`

    ```{r}
    emmeans::emmeans(mod1, specs = "mediana_edad_cat", contr = "pairwise")$contrasts
    ```

------------------------------------------------------------------------

-   Revisemos los supuestos de los residuales en forma gráfica usando `performance:`

    ```{r}
    #| echo: true
    check_model(mod1)
    ```

------------------------------------------------------------------------

-   También podemos usar los test de residuales:

    ```{r}
    #| echo: true
    check_normality(mod1)

    check_heteroscedasticity(mod1)

    check_outliers(mod1)
    ```

------------------------------------------------------------------------

### Colinealidad

-   En los gráficos de residuales observamos la presencia de un nuevo panel correspodiente al **test de colinealidad**:

    ```{r}
    check_model(mod1, check = "vif")
    ```

------------------------------------------------------------------------

-   La **colinealidad** ocurre cuando dos o más variables independientes en un modelo de regresión están **altamente correlacionadas** entre sí, es decir, comparten información redundante.

-   Esto implica que una variable independiente puede ser predicha en gran medida por las otras variables independientes en el modelo.

-   Puede detectarse de dos formas:

    -   Durante el análisis exploratorio observando la matriz de correlación.

    -   En el análisis de residuales por el factor de **inflación de la varianza** (VIF).

------------------------------------------------------------------------

#### Factor de inflación de la varianza (VIF)

-   Mide cuánto aumenta la varianza del coeficiente de una variable independiente debido a su correlación con las otras variables independientes en el modelo.

-   Se calcula como:

    $$
    VIF = \frac{1}{1-R^2_i}
    $$

-   En general:

    -   $VIF = 1$: Ausencia de colinealidad

    -   $1 \geq VIF \geq 5$: Colinealidad moderada

    -   $VIF > 5$: Colinealidad alta

------------------------------------------------------------------------

-   La colinealidad provoca los siguientes problemas:

    -   Aumenta las varianzas y covarianzas de los estimadores
    -   Los errores de las estimaciones serán grandes
    -   Estimadores con valores absolutos grandes
    -   Los coeficientes de cada variable independiente difieren notablemente de los que se obtendrían por RLS
    -   No se puede identificar de forma precisa el efecto individual de cada variable colineal sobre la variable respuesta.

------------------------------------------------------------------------

### Selección de variables explicativas

Al momento de ajustar un modelo de regresión múltiple debemos seguir los siguientes principios:

-   Incluir en los modelos **variables independientes significativas** en modelos simples y aquellas útiles teóricamente.

-   Un modelo con muchas variables no necesariamente es el mejor.

-   Tener en cuenta el tamaño de la muestra:

    -   Cada **variable numérica** resta un **grado de libertad**.

    -   Cada **variable categórica** quita un grado de libertad **por nivel**.

------------------------------------------------------------------------

-   **Colinealidad**: Evaluar y eliminar variables que estén altamente correlacionadas.

-   Priorizar siempre el **principio de parsimonia** (el modelo más simple que mejor explique).

<!-- -->

-   Para ello existen tres estrategias de selección de variables independientes:

    -   *Forward*: ingresando variables independientes a partir de un modelo nulo.

    -   *Stepwise:* añade o quita variables independientes por etapas.

    -   ***Backwards*****: quita variables independientes de un modelo saturado en base al Criterio de Información de Akaike (AIC).**

------------------------------------------------------------------------

#### Criterio de Información de Akaike (AIC)

Es una métrica que evalúa el ajuste del modelo y penaliza la complejidad (número de variables) del mismo.

-   Se calcula como:

    $$
    AIC = 2k - 2\ln(L)
    $$

-   donde:

    -   $k$: Número de parámetros en el modelo.

    -   $L$: Verosimilitud del modelo (probabilidad de que el modelo haya generado los datos observados).

-   Al comparar modelos anidados, **un AIC más bajo indica mejor ajuste**.

------------------------------------------------------------------------

## Ejemplo en R Commander

-   En RCommander podemos seleccionar automáticamente el mejor modelo a partir de un modelo saturado yendo al menú **Modelos \> Selección de modelos paso a paso.**

-   En la nueva ventana seleccionamos las opciones **atrás** y **AIC**.

    ![](images/clipboard-2336083160.png)

------------------------------------------------------------------------

```{r}
steps <- step(mod1, direction = 'backward')
```

-   El mejor modelo elimina la variable `pct_salud_publica`.

-   En general, se toma una diferencia de $\Delta AIC \geq 2$ para elegir entre dos modelos similares.

------------------------------------------------------------------------

-   Si nos interesara ajustar modelos de forma manual y compararlos, el procedimiento a seguir es:

    -   Ajustar el modelo saturado con todas las variables independientes.

    -   Ajustar modelos quitando de a una variable independiente al modelo saturado.

    -   Comparar el modelo saturado y los modelos reducidos usando la función `compare_performance(mod1, mod2, ..., modn)`.

    -   Repetir los pasos anteriores hasta que no se produzcan cambios importantes en el AIC.
